{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from micromlgen import port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100 observations\n",
    "- 2 features (right, left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training set : 100 \n",
      "Amount of validation set: 50\n",
      "Nearest Neighbors: \t 0.96\n",
      "Linear SVM: \t 0.98\n",
      "RBF SVM: \t 1.0\n",
      "Gaussian Process: \t 0.98\n",
      "Decision Tree: \t 0.94\n",
      "Random Forest: \t 1.0\n",
      "AdaBoost: \t 0.96\n",
      "Naive Bayes: \t 1.0\n",
      "QDA: \t 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manos/program_files/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "def load_features(folder):\n",
    "    dataset = None\n",
    "    classmap = {}\n",
    "    for class_idx, filename in enumerate(glob('%s/*.csv' % folder)):\n",
    "        class_name = basename(filename)[:-4]\n",
    "        classmap[class_idx] = class_name\n",
    "        samples = np.loadtxt(filename, dtype=float, delimiter=',')\n",
    "        labels = np.ones((len(samples), 1)) * class_idx\n",
    "        samples = np.hstack((samples, labels))\n",
    "        dataset = samples if dataset is None else np.vstack((dataset, samples))\n",
    "    X, y = dataset[:, :-1], dataset[:, -1]\n",
    "    return X,y,classmap\n",
    "\n",
    "folder = 'dataset/'\n",
    "X,y,classmap = load_features('dataset/')\n",
    "\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=42)\n",
    "\n",
    "print(f\"Amount of training set : {len(X_train)} \\nAmount of validation set: {len(X_test)}\")\n",
    "\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(gamma=0.01, kernel=\"linear\", C=1),\n",
    "    SVC(gamma=0.01, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(20, max_depth=10),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f\"{name}: \\t {score}\")\n",
    "#     print(classification_report(y_test, y_pred, zero_division=True))\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# classifier = SVC(gamma=0.01, kernel=\"linear\", C=1).fit(X_train,y_train)\n",
    "# c_code = port(classifier, classmap=classmap)\n",
    "# print(c_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 90)\n"
     ]
    }
   ],
   "source": [
    "def load_features(folder):\n",
    "    dataset = None\n",
    "    classmap = {}\n",
    "    for class_idx, filename in enumerate(glob('%s/*.csv' % folder)):\n",
    "        class_name = basename(filename)[:-4]\n",
    "        classmap[class_idx] = class_name\n",
    "        samples = np.loadtxt(filename, dtype=float, delimiter=',')\n",
    "        labels = np.ones((len(samples), 1)) * class_idx\n",
    "        samples = np.hstack((samples, labels))\n",
    "        dataset = samples if dataset is None else np.vstack((dataset, samples))\n",
    "    X, y = dataset[:, :-1], dataset[:, -1]\n",
    "    return X,y,classmap\n",
    "\n",
    "folder = 'dataset/'\n",
    "X,y,classmap = load_features('dataset/')\n",
    "#     X = StandardScaler().fit_transform(X)\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(X, y, test_size=.30, random_state=42)\n",
    "print(x_train.shape)\n",
    "# create a NN with 2 la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 90)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52 -0.52 -1.3  -0.38 -0.55 -1.3  -0.68 -1.36 -1.65  0.06 -0.19 -0.13\n",
      "  0.21  0.32  0.32  0.54  0.68  0.91  1.12  0.76  1.16  0.04  0.24 -0.3\n",
      " -0.58 -0.56 -0.45  0.15  0.3   0.8   0.95 -0.47  0.07  1.31  0.93  1.48\n",
      "  0.7  -0.69  0.08  0.43 -0.32  0.65 -1.19 -1.25 -0.63 -0.07 -0.39  0.18\n",
      " -0.67 -0.8   3.43 -7.56  8.42  7.39  5.83  4.36  6.68  7.8   5.28  7.83\n",
      "  6.88  6.61  8.04  6.82  6.04  7.98  8.13 -5.38  6.88  7.27 -7.27  6.05\n",
      "  6.02  6.39  8.19  5.7   6.97  7.37 -3.36 -2.65  5.14  9.72  5.49  5.53\n",
      "  5.43 -3.2   4.13  8.47  7.11  9.3   0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "avg_X = np.zeros([X.shape[0]])\n",
    "avg_Y = np.zeros([X.shape[0]])\n",
    "avg_Z = np.zeros([X.shape[0]])\n",
    "\n",
    "for j in range(avgX.shape[0]):\n",
    "    avg_X[j] = np.asarray([X[j,i:i+1] for i in range(0, avg_X.shape[0], 3)][0]).mean() \n",
    "    avg_Y[j] = np.asarray([X[j,i+1:i+2] for i in range(0, avg_Y.shape[0], 3)][0]).mean()\n",
    "    avg_Z[j] = np.asarray([X[j,i+2:i+3] for i in range(0, avg_Z.shape[0], 3)][0]).mean()\n",
    "\n",
    "avg_dataset = np.column_stack((avg_X, avg_Y, avg_Z))\n",
    "print(avg_X)\n",
    "# np.savetxt(\"averaged_dataset.csv\", avg_dataset, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tinymlgen import port\n",
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
